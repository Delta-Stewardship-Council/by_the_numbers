---
title: "Whats going on in the Delta Wateshed"
---

------------------------------------------------------------------------

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
rm(list=ls())

#install.packages("rvest")
library(rvest)
#install.packages("pdftools")
library(pdftools)
library(tidyverse)
library(stringr)
#install.packages("rvest")
#install.packages("xml2")
library(rvest)
library(xml2)

#install.packages("devtools")
#devtools::install_github("flowwest/CDECRetrieve")
library(CDECRetrieve)

library(magrittr)
#install.packages("leaflet")
library(leaflet)
#install.packages("writexl")
library(writexl)
#install.packages("readxl")
library(readxl)

#install.packages("lubridate")
library(lubridate)
#install.packages("openxlsx")
library(openxlsx)


```

#################### Precipitation

-Crucial to the Delta Watershed as it provides water for the Delta!

-   **Water Supply**

-   **Ecosystem Health**

-   **Agricultural Support**

-   **Flood Control**

-   **Salinity Control**

-   **Hydropower Generation**

-   **Recreation and Tourism**

```{r}

#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
northern_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_ESI.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded

northern_pdf_file<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/northern_sierra.pdf"



# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(northern_pdf_url, northern_pdf_file, mode = "wb")

# Extract text from the PDF
northern_pdf_text <- pdf_text(northern_pdf_file)

# Print the extracted text
#print(northern_pdf_text)

```

###### Current Precipitation for Northern Sierra Region {style="color: darkblue"}

```{r}

# Initialize an empty vector to store the extracted values
N_sierra_current_precip <- c()

# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)

# Print the next four characters following "Current:" in each sentence
if (length(northern_pdf_text) > 0) {
  for (sentence in northern_pdf_text) {
    pattern <- "(?i)Current:\\s?(.{4})"
    match <- regexpr(pattern, sentence, perl = TRUE)
    if (match[1] != -1) {
      northern_next_four <- regmatches(sentence, match)
      # Extract the captured group (the four characters) and append to the vector
      next_four <- sub(pattern, "\\1", northern_next_four)
      N_sierra_current_precip <- c(N_sierra_current_precip, next_four)
      # Print the formatted output as "Current: <next_four>"
      cat(paste("Current:", next_four, "inches"))
    } else {
      cat("Next four characters after 'Current:' not found.")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}




```

Northern Sierra Region: Percent of average rain for this date

```{r}
# Create an empty vector to store the extracted value
N_sierra_average_precip <- c()

# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)

# Check if the PDF text is not empty
if (length(northern_pdf_text) > 0) {
  # Concatenate all the text into a single string
  combined_text <- paste(northern_pdf_text, collapse = " ")
  
  # Define the pattern to match the "Percent of Average for this Date:" followed by the percentage value
  pattern <- "(?i)Percent of Average for this Date:\\s*(\\d+%)"
  
  # Extract the match using regmatches and regexpr
  northern_next_four <- regmatches(combined_text, regexpr(pattern, combined_text, perl = TRUE))
  
  if (length(northern_next_four) > 0) {
    # Extract the percentage value using a capturing group
    percent_value <- sub("(?i)Percent of Average for this Date:\\s*(\\d+%)", "\\1", northern_next_four)
    
    # Append the value to the vector
    N_sierra_average_precip <- c(N_sierra_average_precip, percent_value)
    
    # Print only the percentage value
    cat(percent_value, "\n")
  } else {
    cat("Percent of Average for this Date not found.\n")
  }
} else {
  cat("No text extracted from the PDF.\n")
}



```

Current Precipitation for Central Sierra Region

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

#Central Sierra precipitation #Pulling and downloading the pdf from online
#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
central_ppt_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_FSI.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
central_ppt_pdf_file2<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/central_sierra2.pdf"

# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(central_ppt_pdf_url, central_ppt_pdf_file2, mode = "wb")

# Extract text from the PDF
central_pdf_text <- pdf_text(central_ppt_pdf_file2)

# Print the extracted text
print(central_pdf_text)

```

Central Sierra Region: Percent of average rain for this date

```{r}

#Central Sierra #PUlling out Percent average

#create an empty vector
Central_average_precip <- c()

# Print the next four characters following "Current:" in each sentence
if (length(central_pdf_text) > 0) {
  for (sentence in central_pdf_text) {
    pattern <- "(?i)Percent of Average for this Date:\\s?(.{4})"
    next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
    if (length(next_four) > 0) {
      # Append the value of next_four to the vector
      Central_average_precip <- c(Central_average_precip, next_four)
      cat(paste(next_four))
    } else {
      cat("Next four characters after 'Current:' not found.")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}




```

# Central Sierra

###### Current Precipitation for Central Sierra Region {style="color: darkblue"}

```{r}
#create an empty vector 
Central_current_precip <- c()

# Print the next four characters following "Current:" in each sentence
if (length(central_pdf_text) > 0) {
  for (sentence in central_pdf_text) {
    pattern <- "(?i)Current:\\s?(.{4})"
    next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
    if (length(next_four) > 0) {
      # Append the value of next_four to the vector
      Central_current_precip <- c(Central_current_precip, next_four)
      cat(paste( next_four, "inches"))
    } else {
      cat("Next four characters after 'Current:' not found.")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}


```

#################################################################################### 

#################### SNOW PACK

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
snow_pack_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/swccond.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
snow_pack_pdf_file<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/snow_pack.pdf"

# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(snow_pack_pdf_url, snow_pack_pdf_file, mode = "wb")

# Extract text from the PDF
snow_pack_pdf_text <- pdf_text(snow_pack_pdf_file)

# Print the extracted text
print(snow_pack_pdf_text)


```

#North Snow average snow pack

```{r}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)NORTH\\s{2,}(\\d+%).*?(\\d+%)"

# Extract the "NORTH" section
north_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the "NORTH" section is found
if (length(north_match) > 0) {
  # Extract both percentages from the matched text
  north_percentages <- regmatches(north_match[[1]], gregexpr("\\d+%", north_match[[1]]))[[1]]
  
  # Print the extracted percentage
  if (length(north_percentages) >= 2) {
    cat(paste("Northern CA:", north_percentages[2], "of percent avgerage to date snow pack"))
  } else {
    cat("Second percentage in the 'NORTH' section not found.")
  }
} else {
  cat("NORTH section not found.")
}

```

#north snow water equivalent

```{r}

# Define the pattern to match the line containing the snow water equivalent information
pattern <- "(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)"

# Extract the line containing snow water equivalent information
snow_water_line <- regmatches(snow_pack_pdf_text, regexpr(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the line is found
if (length(snow_water_line) > 0) {
  # Extract the numeric value
  numeric_value <- sub("(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)", "\\1", snow_water_line)
  
  # Create the modified line with "inches" after the numeric value
  modified_snow_water_line <- paste("average snow water equivalent", numeric_value, "inches")
  
  cat("Northern Sierra", modified_snow_water_line, "\n")
} else {
  cat("Snow water equivalent information not found.\n")
}


```

#Central % Snow average snow pack

```{r}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)CENTRAL SIERRA\\s{2,}(\\d+%).*?(\\d+%)"

# Extract the "CENTRAL SIERRA" section
central_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the "CENTRAL SIERRA" section is found
if (length(central_match) > 0) {
  # Extract both percentages from the matched text
  central_percentages <- regmatches(central_match[[1]], gregexpr("\\d+%", central_match[[1]]))[[1]]
  
  # Print the extracted percentage
  if (length(central_percentages) >= 2) {
    cat(paste("CENTRAL SIERRA", central_percentages[2], "of percent avg. to date snow pack"))
  } else {
    cat("Second percentage in the 'CENTRAL SIERRA' section not found.")
  }
} else {
  cat("CENTRAL SIERRA section not found.")
}


```

#Central snow water equivalent

```{r}


# Find the position of "Central Sierra" in the text
central_sierra_position <- regexpr("(?i)Central Sierra", snow_pack_pdf_text)

# If "Central Sierra" is found, find the position of "Average snow water equivalent (Inches)" after it
if (central_sierra_position > 0) {
  # Get the substring starting from the position of "Central Sierra"
  substring_after_central <- substring(snow_pack_pdf_text, central_sierra_position)
  
  # Find the position of "Average snow water equivalent (Inches)" within the substring
  snow_water_position <- regexpr("(?i)Average snow water equivalent \\(Inches\\)", substring_after_central)
  
  # If "Average snow water equivalent (Inches)" is found, extract the numeric value following it
  if (snow_water_position > 0) {
    # Get the substring starting from the position of "Average snow water equivalent (Inches)"
    snow_water_substring <- substring(substring_after_central, snow_water_position)
    
    # Extract the numeric value following "Average snow water equivalent (Inches)"
    snow_water_value <- regmatches(snow_water_substring, regexpr("\\d+\\.\\d+", snow_water_substring))
    
    # If a numeric value is found, print it with the desired text
    if (length(snow_water_value) > 0) {
      cat(paste("Central snow water equivalent", snow_water_value))
    } else {
      cat("Snow water equivalent value not found.")
    }
  } else {
    cat("Average snow water equivalent information not found for Central Sierra.")
  }
} else {
  cat("Central Sierra information not found.")
}


```

# State wide average snow pack: water year

```{r}

# Find the position of "State" in the text
state_position <- regexpr("(?i)State", snow_pack_pdf_text)

# If "State" is found, find the position of the numeric value after it
if (state_position > 0) {
  # Get the substring starting from the position of "State"
  substring_after_state <- substring(snow_pack_pdf_text, state_position)
  
  # Extract the numeric value following "State"
  snow_water_value <- regmatches(substring_after_state, regexpr("\\d+\\.\\d+", substring_after_state))
  
  # If a numeric value is found, print it with the desired text
  if (length(snow_water_value) > 0) {
    cat(paste("State wide average snow pack", snow_water_value))
  } else {
    cat("Snow water equivalent value not found.")
  }
} else {
  cat("State information not found.")
}


```

#Percent of normal snow pack for this date (%)

```{r}

# Find the position of "Statewide Average:" in the text
statewide_position <- regexpr("(?i)Statewide Average:", snow_pack_pdf_text)

# If "Statewide Average:" is found, find the position of the numeric value after it
if (statewide_position > 0) {
  # Get the substring starting from the position of "Statewide Average:"
  substring_after_statewide <- substring(snow_pack_pdf_text, statewide_position)
  
  # Extract both percentages from the matched text
  statewide_percentages <- regmatches(substring_after_statewide, gregexpr("\\d+%", substring_after_statewide))[[1]]
  
  # Print the second percentage with the desired text
  if (length(statewide_percentages) >= 2) {
    cat("Statewide average percent snow pack for this date", statewide_percentages[2], "\n")
  } else {
    cat("Second percentage after 'Statewide Average:' not found.")
  }
} else {
  cat("Statewide Average information not found.\n")
}



```

################### Reservoir Storage

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

# URL of the website to scrape
reservoir_url <- "https://cdec.water.ca.gov/reportapp/javareports?name=RES"

# Read the web page
reservoir_web_page <- read_html(reservoir_url)

# Extract the table node
reservoir_table_node <- html_node(reservoir_web_page, "table")

# Extract the table content into a data frame
reservoir_table_data <- html_table(reservoir_table_node)

# Print the entire table data
print(reservoir_table_data)

# Extract a specific numbers [row, column]
#Shasta (at Sacramento River)
#extract percent of average storage
shasta_percent_average_storage <- reservoir_table_data[10, 9]
print(shasta_percent_average_storage)
#extract percent of capacity
shasta_percent_capacity<-reservoir_table_data[10,7]
print(shasta_percent_capacity)


# Extract a specific numbers [row, column]
#Oroville (at Feather River)
#extract percent of average storage
oroville_percent_average_storage <- reservoir_table_data[13, 9]
print(oroville_percent_average_storage)
#extract percent of capacity
oroville_percent_capacity<-reservoir_table_data[13,7]
print(oroville_percent_capacity)


# Extract a specific numbers [row, column]
#San Luis (at San Luis Creek)
#extract percent of average storage
SanLuis_percent_average_storage <- reservoir_table_data[56, 9]
print(SanLuis_percent_average_storage)
#extract percent of capacity
SanLuis_percent_capacity<-reservoir_table_data[56,7]
print(SanLuis_percent_capacity)

```

################### Flow Sacramento

#collapsed code chunk makes a bad map of sacramento sensors

```{r}

#this makes a map of all sacramento CDEC stations
cdec_stations(county = "sacramento") %>% 
  map_stations()

```

```{r}
#This code helps identify where numbers respond to which sensors for each station


#find which number corresponds to the correct sensor for Sacramento 
#station_FPT <- "FPT"
#cdec_datasets("FPT")

#find which number corresponds to the correct sensor for Vernalis
#station_VNS <- "VNS"
#cdec_datasets("VNS")


```

```{r}

#Create data set of exports from Sacramento and San Joaquin River at Vernalis #take Monthly average of those data sets 

###################        Sacramento     #############################
#Each month need to change "start_date" (Year, Month, Day)
#sensor number is determined by the previous code chunk (do not need to change)

#Sacramento
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
sac_flow_daily <- cdec_query(station = "FPT", sensor_num = 20, 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))


#need to take the average of all parameter_value for the date 
sacramento_export_monthly_average<-mean(sac_flow_daily$parameter_value, na.rm = T)
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
###################  San Joaquin River at Vernalis  #####################

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

#  ***** dur_code = "D" not working, --> should theoretically get same values using "H" (hourly)
# Query CDEC data from the first of the month to the current date
SanJoaquin_flow_daily <- cdec_query(station = "VNS", sensor_num = 20, 
                                    dur_code = "H", start_date = as.character(start_date), 
                                    end_date = as.character(end_date))

# View the result
print(SanJoaquin_flow_daily)
```

#San Joaquin monthly average export

```{r}

#need to take the average of all parameter_value for the date 
SanJoaquin_export_monthly_average<-mean(SanJoaquin_flow_daily$parameter_value, na.rm = T)
SanJoaquin_export_monthly_average
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

#Total Delta Exports: 'total delta exports', average of (CVP + SWP) 

#When run, will automatically update for current month
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"

# Path to save the downloaded PDF file
delta_exports_pdf_file <- "C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/delta_exports.pdf"

# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")

# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)

print(delta_exports_pdf_text)



delta_export_first_page_text <- delta_exports_pdf_text[1]

# Print the extracted text to determine the pattern
print(delta_export_first_page_text)

# Split the text into lines
delta_export_lines <- str_split(delta_export_first_page_text, "\n")[[1]] 
#"\n" is the new line character, splits the text into lines
#[[1]] extracts the first element from the list 



# Extract lines containing the table data
delta_export_table_lines <- delta_export_lines[str_detect(delta_export_lines, "\\d{2,4}")]

# Split each line into columns based on whitespace
delta_export_table_data <- map(delta_export_table_lines, ~str_split(.x, "\\s+")[[1]])

# Find the maximum number of columns
delta_export_max_cols <- max(sapply(delta_export_table_data, length))

# Pad shorter rows with NA values
delta_export_padded_table_data <- lapply(delta_export_table_data, function(row) {
  length(row) <- delta_export_max_cols
  row
})

# Convert the padded list of lists into a data frame
delta_export_table_df <- do.call(rbind, lapply(delta_export_padded_table_data, function(x) data.frame(matrix(x, ncol = delta_export_max_cols, byrow = TRUE), stringsAsFactors = FALSE)))

# Print the data frame
print(delta_export_table_df)
```

#Total Delta Exports: 'total delta exports', average of (CVP + SWP)

```{r}

# Extract a specific number (example: first row, second column)
average_delta_export_value<-delta_export_table_df[36, 17]
print(average_delta_export_value)

```

##\*\*\* figure out way to add data from this year to historical after year ends #somethign that updates only on specific dates #Need to create a output csv file for historical data

```{r}
# read_xlxs() by default reads in the first sheet. There may however be numerous sheets in the file. We can tell R which sheet to read in as well as how many lines to skip before reading in data

#tells R to skip 6 lines and then read in the second sheet of an xlsx file
#metadata<-read_xlsx("data/calenviroscreen/ces3results.xlsx", 
 #                     sheet = 2, 
  #                    skip  = 6)

#as of now data has to be added manually at the end of the year to the historical data set

```

################################## Salinity

#Sacramento River at Hood (station code SRH) #When run, will automatically update for current month

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
sac_cond_daily_new <- cdec_query(station = "SRH", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))
Sac_cond_monthly_average<-mean(sac_cond_daily_new$parameter_value, na.rm = T)
Sac_cond_monthly_average

#### ppm conversion
sac_ppm<-(Sac_cond_monthly_average*0.55)


```

#San Joaquin River at Vernalis (station code - VER) #When run, will automatically update for current month

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SanJoaquin_cond_daily_new <- cdec_query(station = "VER", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))


SanJoaquin_cond_monthly_average<-mean(SanJoaquin_cond_daily_new$parameter_value, na.rm = T)
SanJoaquin_cond_monthly_average

#### ppm conversion
SanJoa_ppm<-(SanJoaquin_cond_monthly_average*0.55)
SanJoa_ppm
```

#Salinity at Banks pumping plant (station code - HBP) #When run, will automatically update for current month

```{r}


# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
Banks_cond_daily_new <- cdec_query(station = "HBP", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
Banks_cond_monthly_average<-mean(Banks_cond_daily_new$parameter_value, na.rm = T)
Banks_cond_monthly_average


#convert um/cm to ppm
#idea to have some historical context with the salinity?
#### ppm conversion
Banks_ppm<-(Banks_cond_monthly_average*0.55)
Banks_ppm
```

####################### TEMPERATURE

#need to add hisotrical average data in --\> will add to csv file eventually

#Water Temp - Sacramento river headwaters at Clear Creek

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SacClearCreek_waterTemp_new <- cdec_query(station = "IGO", sensor_num = "25", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
SacClearCreek_waterTemp_monthly_average<-mean(SacClearCreek_waterTemp_new$parameter_value, na.rm = T)
SacClearCreek_waterTemp_monthly_average



#cdec_datasets("IGO")

```

#Water Temp - Sacramento/San Joaquin Rivers confluence at Collinsville

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SacSanJoaquin_waterTemp_new <- cdec_query(station = "CSE", sensor_num = "25", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
SacSanJoaquin_waterTemp_monthly_average<-mean(SacSanJoaquin_waterTemp_new$parameter_value, na.rm = T)
SacSanJoaquin_waterTemp_monthly_average


```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

#Water Temp - South Delta (near HBP) at Clifton Court Forebay

cdec_datasets("CLC")

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SouthDelta_waterTemp_new <- cdec_query(station = "CLC", sensor_num = "146", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#because CLC temp gage only have readings in Celcius, need to convert to F

SouthDelta_waterTemp_new$parameter_F<-(SouthDelta_waterTemp_new$parameter_value*( 9/5) + 32)
```

#Water Temp - South Delta (near HBP) at Clifton Court Forebay

```{r}
#need to take the average of all parameter_value for the date 
SouthDelta_waterTemp_monthly_average_F<-mean(SouthDelta_waterTemp_new$parameter_F, na.rm = T)
SouthDelta_waterTemp_monthly_average_F

```
